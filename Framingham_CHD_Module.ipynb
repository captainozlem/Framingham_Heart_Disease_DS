{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import statistics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the custom scaler class\n",
    "\n",
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns,copy=True, with_mean=True, with_std=True):\n",
    "        self.scaler = StandardScaler(copy,with_mean,with_std)\n",
    "        self.columns = columns\n",
    "        self.mean_= None\n",
    "        self.var_ = None\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        self.scaler.fit(X[self.columns],y)\n",
    "        self.mean_ =np.array(np.mean(X[self.columns]))\n",
    "        self.var_ = np.array(np.var(X[self.columns]))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X,y=None, copy=None):\n",
    "        init_col_order = X.columns\n",
    "        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)\n",
    "        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]\n",
    "        return pd.concat([X_not_scaled,X_scaled],axis=1)[init_col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the special class that we are going to use from here on to predict new data\n",
    "class Framingham_CHD_model_model():\n",
    "      \n",
    "        def __init__(self, model_file, scaler_file):\n",
    "            # read the 'model' and 'scaler' files which were saved\n",
    "            with open('Framingham_CHD_model','rb') as model_file, open('scaler', 'rb') as scaler_file:\n",
    "                self.reg = pickle.load(model_file)\n",
    "                self.scaler = pickle.load(scaler_file)\n",
    "                self.data = None\n",
    "        \n",
    "        # take a data file (*.csv) and preprocess it in the same way as in the lectures\n",
    "        def load_and_clean_data(self, data_file):\n",
    "            \n",
    "            # import the data\n",
    "            df = pd.read_csv(data_file,delimiter=',')\n",
    "            # store the data in a new variable for later use\n",
    "            self.df_with_predictions = df.copy()\n",
    "            \n",
    "            #Dropping missing education data\n",
    "            edu_missing = df[df['education'].isnull()].index\n",
    "            df = df.drop(edu_missing)\n",
    "            \n",
    "            ## cigsPerDay can be both, so I will check if the same index of the missing data current smoker or not,\n",
    "            ## if not null data will fill with 0, or median\n",
    "            cigarette_index = df[df['cigsPerDay'].isnull()].index\n",
    "            smokers = df[df['currentSmoker'] == 1].index\n",
    "            \n",
    "            ##I will create a cigarettes array using smokers indeces. So, I will get the median only from smokers (almost half of the participants are non smokers, reduces the mean( Median turns 0 without checking only smokers)\n",
    "            cigarettes_by_smokers = []\n",
    "            for i in smokers:\n",
    "                 if df['cigsPerDay'][i] != 'nan':\n",
    "                    cigarettes_by_smokers.append(df['cigsPerDay'][i])\n",
    "            \n",
    "            ## Finding the median cigarettes per day based on smokers\n",
    "            smoker_median = statistics.median(cigarettes_by_smokers)\n",
    "            \n",
    "            ## All of the missing values in cigsPerDay actually current smokers so, i will replace missing values with mean\n",
    "            df['cigsPerDay'] = df['cigsPerDay'].fillna(smoker_median)\n",
    "            \n",
    "            ## BPMed missing values: I made some research on Google, so if your blood pressure is higher than 140-90 \n",
    "            ## Doctors are recommending to take BPMed. So, I will check if sysBP is higher than 140 and/or diaBP is higher \n",
    "            ## than 90, if so I will switch NaN values to 1 or 0\n",
    "            BP_missing_index = df[df['BPMeds'].isnull()].index\n",
    "            \n",
    "            for i in BP_missing_index:\n",
    "                if ( df['sysBP'][i] > 140 or df['diaBP'][i] > 90 ):\n",
    "                    df.loc[i,'BPMeds'] = 1.0  \n",
    "            else:\n",
    "                df.loc[i,'BPMeds'] = 0.0\n",
    "                \n",
    "            \n",
    "            ## I will going fill rest of the NaN value with mean values\n",
    "            df['totChol'] = df['totChol'].fillna(round(df['totChol'].mean()))\n",
    "            df['BMI'] = df['BMI'].fillna(df['BMI'].mean())\n",
    "            df['glucose'] = df['glucose'].fillna(round(df['glucose'].mean()))\n",
    "            \n",
    "            ## There is only one missing value in heart rate, I will use bfill method for replacing NA value\n",
    "            ## will bfill it replaces the value that comes directly after it in the same column\n",
    "            df['heartRate'] = df['heartRate'].fillna(method='bfill', axis=0)\n",
    "            \n",
    "            ## I will re-group them 0: Less than High School and High School degrees, 1: College Degree and Higher\n",
    "            df[\"education\"] = df[\"education\"].map({1.0:0, 2.0:0, 3.0:1, 4.0:1})\n",
    "\n",
    "            # we have included this line of code if you want to call the 'preprocessed data'\n",
    "            self.preprocessed_data = df.copy()\n",
    "            \n",
    "            # we need this line so we can use it in the next functions\n",
    "            self.data = self.scaler.transform(df)\n",
    "    \n",
    "        # a function which outputs the probability of a data point to be 1\n",
    "        def predicted_probability(self):\n",
    "            if (self.data is not None):  \n",
    "                pred = self.reg.predict_proba(self.data)[:,1]\n",
    "                return pred\n",
    "        \n",
    "        # a function which outputs 0 or 1 based on our model\n",
    "        def predicted_output_category(self):\n",
    "            if (self.data is not None):\n",
    "                pred_outputs = self.reg.predict(self.data)\n",
    "                return pred_outputs\n",
    "        \n",
    "        # predict the outputs and the probabilities and \n",
    "        # add columns with these values at the end of the new data\n",
    "        def predicted_outputs(self):\n",
    "            if (self.data is not None):\n",
    "                self.preprocessed_data['Probability'] = self.reg.predict_proba(self.data)[:,1]\n",
    "                self.preprocessed_data ['Prediction'] = self.reg.predict(self.data)\n",
    "                return self.preprocessed_data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
